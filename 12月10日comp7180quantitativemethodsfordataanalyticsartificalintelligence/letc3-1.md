# 1-33
# 2-33
这页内容主要讨论了特征值和特征向量的概念。

### 矩阵-向量乘法
- 表示为 \( Ax \)，几乎所有的向量在与矩阵 \( A \) 相乘时都会改变其方向。

### 特征向量
- “Eigen” 是德语，意为“特性”或“特征”。
- 存在某些特殊的向量 \( x \)，其方向与 \( Ax \) 相同。
- 与矩阵 \( A \) 相乘不会改变这些向量的方向。
- 这些特殊的向量被称为矩阵 \( A \) 的“特征向量”。

### 特征值
- 对于这些特征向量，与矩阵 \( A \) 的乘积等于该特征向量乘以一个数。
- 因此，可以写作 \( Ax = \lambda x \)。
- 其中的数字 \( \lambda \) 被称为矩阵 \( A \) 的特征值。

总结来说，这一页讨论的是如何通过矩阵与向量的乘法来定义特征向量和特征值。特征向量是能保持方向不变的特殊向量，而特征值则是与特征向量相关联的标量。
# 3-33
这一页的内容继续讨论特征值和特征向量的概念，具体涉及特征值方程及其几何意义。

### 特征值方程
- 特征值方程写作 \( Ax = \lambda x \)。
  - 其中 \( A \) 是一个矩阵，\( x \) 是特征向量，\( \lambda \) 是特征值。

### 特征值的意义
- 特征值 \( \lambda \) 表示在通过矩阵 \( A \) 乘以特征向量 \( x \) 时：
  - 该特征向量会被拉伸、缩小，或者反向（即方向改变），或者保持不变。
  - 换句话说，特征值决定了特征向量在变换下的变化性质。

### 示例
- 给出了一个具体的矩阵乘法例子：
  - \( \begin{pmatrix} 4 & 2 \\ 3 & 0 \end{pmatrix} \begin{pmatrix} 2 \\ 1 \end{pmatrix} = 5 \begin{pmatrix} 2 \\ 1 \end{pmatrix} \)
  - 这里，矩阵 \( A \) 作用于特征向量 \( \begin{pmatrix} 2 \\ 1 \end{pmatrix} \)，结果是特征值 \( 5 \) 乘以该特征向量。

### 视觉表示
- 右侧示意图显示了特征向量的方向，及其经过矩阵 \( A \) 变换后的新方向。
- 显示的绿色箭头表明在乘法后，特征向量的方向和长度（被拉长至 \( \begin{pmatrix} 10 \\ 5 \end{pmatrix} \)）的变化。

总之，这一页强调特征值方程的重要性，以及它如何影响特征向量的变换，提供了一个具体的例子以帮助理解这一概念。
# 4-33
这一页讨论了特征值和特征向量的特殊情况，尤其是单位矩阵的特性。

### 单位矩阵的特性
- 如果 \( A \) 是单位矩阵（identity matrix），那么对于任何向量 \( x \)，都有 \( Ax = x \)。
  - 这意味着单位矩阵不会改变任何向量的方向或大小，每个向量在与单位矩阵相乘后都保持不变。

### 特征向量与特征值
- 在单位矩阵的情况下，所有的向量都是该矩阵的特征向量。
- 因为特征值方程 \( Ax = \lambda x \) 中，当 \( A \) 是单位矩阵时，可以得出：
  - 结果是 \( \lambda = 1 \)
  - 所以，所有的特征值都等于 1。

### 示例
- 下面给出两个具体的矩阵与向量的乘法例子：
  
  1. 
  \[
  \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 2 \\ 1 \end{pmatrix} = \begin{pmatrix} 2 \\ 1 \end{pmatrix}
  \]
  - 这个例子展示了单位矩阵与向量 \( \begin{pmatrix} 2 \\ 1 \end{pmatrix} \) 的乘法，结果仍然是该向量。

  2.
  \[
  \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} \begin{pmatrix} 3 \\ 1 \end{pmatrix} = \begin{pmatrix} 3 \\ 1 \end{pmatrix}
  \]
  - 这里同样展示了单位矩阵与另一个向量 \( \begin{pmatrix} 3 \\ 1 \end{pmatrix} \) 的乘法，结果也保持不变。

### 总结
这一页强调了单位矩阵的特殊性，它会使所有向量保持不变，并且所有的特征值均为 1。通过具体的数学例子，进一步说明了这一特性。
# 5-33
这一页主要讲述了计算特征值和特征向量的前提条件，即矩阵的可逆性条件。

### 可逆性条件
可逆性是指矩阵 \( A \) 是否存在逆矩阵 \( A^{-1} \)，这里列出了几个关键条件：

1. **唯一解性**
   - 方程 \( Ax = b \) 对于每一个 \( b \) 都有唯一解。
   - 这意味着不同的 \( b \) 不会导致相同的 \( x \)，确保每次都有一个清晰、明确的解。

2. **零解性**
   - 方程 \( Ax = 0 \) 只有零解 \( x = 0 \)。
   - 这表明矩阵 \( A \) 没有非零的解，也就是说其列向量是线性独立的。

3. **线性独立性**
   - 矩阵 \( A \) 的行或列是线性独立的。
   - 线性独立性确保没有行或列可以通过其他行或列的线性组合表示，这对于矩阵的可逆性至关重要。

4. **行列式非零**
   - 矩阵 \( A \) 的行列式不为零（\(\text{det}(A) \neq 0\)）。
   - 行列式为零意味着矩阵是奇异的，不可逆，不存在逆矩阵。

5. **特征值条件**
   - 零不是矩阵 \( A \) 的特征值。
   - 如果零是特征值，说明矩阵 \( A \) 不可逆，从而失去了线性独立性，可能导致不能唯一确定解。

### 总结
综上所述，这一页列出了确保矩阵 \( A \) 可逆的重要条件。这些条件是计算特征值和特征向量的基本前提，确保在进行相关计算时，矩阵的性质是满足可逆性的。
# 6-33
这一页讨论了计算特征值和特征向量的具体步骤，基于特征值方程 \( Ax = \lambda x \)。

### 计算特征值和特征向量
- **特征值方程**: 我们从特征值方程 \( Ax = \lambda x \) 开始。

### 重写方程
- 将方程重写为 \( (A - \lambda I)x = 0 \)。
  - 这里 \( I \) 是单位矩阵，\(\lambda I\) 代表 \(\lambda\) 乘以单位矩阵。
  - 这种重写表示矩阵 \( (A - \lambda I) \) 与特征向量 \( x \) 相乘，结果为零向量。

### 整体理解
- **指向**: 我们不关注平凡解 \( x = 0 \)，因为任何矩阵与零向量相乘都会得到零向量。
- 我们希望找到非零特征向量 \( x \)。

### 首先获取特征值
- 要获得特征向量，首先必须找到特征值。
- 这需要确保矩阵 \( A - \lambda I \) 是不可逆的（即存在非零解 \( x \)）。
- 因此，我们需要满足条件：
  \[
  \text{det}(A - \lambda I) = 0
  \]
  - 这个方程只涉及参数 \(\lambda\)，而不涉及特征向量 \( x \)。
  
### 对于每个特征值
- 一旦找到了特征值 \(\lambda\)，需要解方程 \( (A - \lambda I)x = 0 \) 来找到相应的特征向量 \( x \)。
- 这个过程会给出与特征值对应的特征向量。

### 总结
这一页提供了计算特征值和特征向量的步骤和逻辑流程，强调了从特征值方程出发，通过代数变换获得解的必要性。最终的目标是找到特征值及其对应的特征向量，揭示它们之间的关系。
# 7-33
这一页提供了计算特征值和特征向量的具体示例，使用一个 \(2 \times 2\) 的矩阵 \( A \) 来说明过程。

### 示例介绍
- 目标是找到以下 \(2 \times 2\) 矩阵 \( A \) 的特征值和特征向量：
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]

### 计算 \(A - \lambda I\)
- 为了计算特征值，首先需要从矩阵 \( A \) 的对角元素中减去特征值 \( \lambda \)：
  \[
  A - \lambda I = \begin{pmatrix} 4 - \lambda & 2 \\ 1 & 3 - \lambda \end{pmatrix}
  \]

### 求解特征值
- 通过求解行列式 \( \text{det}(A - \lambda I) = 0 \) 来找出特征值：
  \[
  \text{det}(A - \lambda I) = (4 - \lambda)(3 - \lambda) - 2 \times 1
  \]

### 展开行列式
- 将行列式展开：
  \[
  (4 - \lambda)(3 - \lambda) - 2 = 12 - 4\lambda - 3\lambda + \lambda^2 - 2 = \lambda^2 - 7\lambda + 10 = 0
  \]
  
### 找特征值
- 这个二次方程 \( \lambda^2 - 7\lambda + 10 = 0 \) 可以通过因式分解或使用求根公式求解得到：
  \[
  (\lambda - 2)(\lambda - 5) = 0
  \]
- 由此得出特征值：
  - \( \lambda_1 = 2 \)
  - \( \lambda_2 = 5 \)

### 总结
这一页通过一个具体的例子详细说明了如何计算特征值。流程包括从矩阵中减去 \( \lambda I \)，求解行列式并展开，最终找到特征值。这个过程为后续计算特征向量打下基础。
# 8-33
这一页展示了如何计算特征向量，通过解方程 \( (A - \lambda I)x = 0 \)。我们将分别为特征值 \( \lambda_1 = 2 \) 和 \( \lambda_2 = 5 \) 找到特征向量。

### 计算特征向量
- 我们首先需要为每个特征值 \( \lambda \) 解方程 \( (A - \lambda I)x = 0 \)。

### 定义向量
- 设向量 \( x \) 表示为：
  \[
  x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}
  \]

### 处理第一个特征值 \( \lambda_1 = 2 \)
1. 将特征值代入方程，得到 \( A - 2I \)：
   \[
   A - 2I = \begin{pmatrix} 4 - 2 & 2 \\ 1 & 3 - 2 \end{pmatrix} = \begin{pmatrix} 2 & 2 \\ 1 & 1 \end{pmatrix}
   \]
2. 解方程 \( (A - 2I)x = 0 \)：
   \[
   \begin{pmatrix} 2 & 2 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 这会导致以下方程组：
   - \( 2x_1 + 2x_2 = 0 \)
   - \( x_1 + x_2 = 0 \)

### 解方程
- 从方程 \( x_1 + x_2 = 0 \) 中，可以得到 \( x_2 = -x_1 \)。
- 所以，任何向量形式为：
  \[
  x = \begin{pmatrix} x_1 \\ -x_1 \end{pmatrix} = x_1 \begin{pmatrix} 1 \\ -1 \end{pmatrix}
  \]
- 例如，向量 \( \begin{pmatrix} -1 \\ -1 \end{pmatrix} \) 或 \( \begin{pmatrix} -2 \\ 2 \end{pmatrix} \) 都是特征值为 \( 2 \) 的特征向量。

### 总结
这一页通过计算特征向量展示了如何从特征方程得到特征值。对于特征值 \( \lambda_1 = 2 \)，我们找到了相应的特征向量的形式，并指出了特征向量和不同数值的多样性。这为理解特征向量和特征值之间的关系提供了具体的示例。
# 9-33
这一页继续展示了如何计算特征向量，这次针对特征值 \( \lambda_2 = 5 \)。

### 计算特征向量
- 我们需要解方程 \( (A - \lambda I)x = 0 \)，从而找出对应于特征值 \( \lambda_2 = 5 \) 的特征向量。

### 定义向量
- 仍然用以下方式定义向量:
  \[
  x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix}
  \]

### 处理第二个特征值 \( \lambda_2 = 5 \)
1. 将特征值代入，得到 \( A - 5I \)：
   \[
   A - 5I = \begin{pmatrix} 4 - 5 & 2 \\ 1 & 3 - 5 \end{pmatrix} = \begin{pmatrix} -1 & 2 \\ 1 & -2 \end{pmatrix}
   \]
2. 解方程 \( (A - 5I)x = 0 \)：
   \[
   \begin{pmatrix} -1 & 2 \\ 1 & -2 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 这会导致如下方程组：
   - \( -x_1 + 2x_2 = 0 \)
   - \( x_1 - 2x_2 = 0 \)

### 解方程
- 从第一个方程 \( -x_1 + 2x_2 = 0 \) 中，可以得到 \( x_1 = 2x_2 \)。
- 所以任何向量可以表示为：
  \[
  x = \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 2x_2 \\ x_2 \end{pmatrix}
  \]
- 例如，可以选择 \( x_2 = 1 \)，得到特征向量 \( \begin{pmatrix} 2 \\ 1 \end{pmatrix} \)（也可以是 \( \begin{pmatrix} 4 \\ 2 \end{pmatrix} \) 等）。

### 总结
这一页通过针对特征值 \( \lambda_2 = 5 \) 的实例，展示了如何找到相应的特征向量。通过代入特征值并求解 \( (A - 5I)x = 0 \)，得到了有关特征向量的形式，并指出特征向量可以有多种表示，强调了它与特征值之间的关系。
# 10-33
这一页讨论了特征向量的非唯一性，即对于给定的特征值，可能存在多个不同的特征向量。

### 特征向量的非唯一性
- 在之前的示例中，我们看到了两个特征向量：
  \[
  \begin{pmatrix} 2 \\ 1 \end{pmatrix} \quad \text{和} \quad \begin{pmatrix} 4 \\ 2 \end{pmatrix}
  \]
  都是对应特征值 5 的特征向量。
- 任何非零倍数的 \( \begin{pmatrix} 2 \\ 1 \end{pmatrix} \) 也是特征向量。这意味着存在一整条特征向量的线。

### 说明非唯一性
- **非唯一特征向量的定义**：
  - 如果 \( x \) 是特征值 \( \lambda \) 的特征向量，且 \( c \) 是任意非零常数，那么 \( cx \) 也是特征向量，并且具有相同的特征值。
  
### 数学表达
- 采用数学表达式来说明这一点：
  \[
  A(cx) = c(Ax) = c(\lambda x) = \lambda (cx)
  \]
  - 这里展示了，如果 \( x \) 是 \( Ax = \lambda x \) 的解，那么 \( cx \) 也使得方程成立，表明它也是特征向量。

### 总结
这一页强调了特征向量的非唯一性，指出对于相同特征值的特征向量，不仅存在多个特征向量，而且任何非零的倍数也是有效的特征向量。这一点对于理解特征向量的空间结构非常重要。
# 11-33
这一页回顾了之前的示例，并引入了新的思考问题，关于其他矩阵的特征值和特征向量。

### 先前示例回顾
- 在之前的示例中，我们对矩阵 
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]
  计算了特征值和特征向量。
- 得到了两组结果：
  - 特征值 \( \lambda_1 = 2 \)，对应的特征向量是 
    \[
    \begin{pmatrix} 2 \\ 1 \end{pmatrix}
    \]
  - 特征值 \( \lambda_2 = 5 \)，对应的特征向量是 
    \[
    \begin{pmatrix} 1 \\ -1 \end{pmatrix}
    \]

### 进一步思考
- 接下来的问题是：如果考虑矩阵 \( A + 3I \) 和 \( A^2 \)，它们的特征值和特征向量会是什么？

### 新矩阵的特征值与特征向量
- 这里可以做一些推测：
  - **对于矩阵 \( A + 3I \)**：
    - 如果原特征值为 \( \lambda \)，那么添加常数 \( c \)（在这儿是 3）就会导致新的特征值为 \( \lambda + c \)。
    - 所以，特征值 \( \lambda_1 + 3 = 5 \) 和 \( \lambda_2 + 3 = 8 \)。
  
  - **对于矩阵 \( A^2 \)**：
    - 特征值的平方：如果 \( \lambda \) 是特征值，那么 \( \lambda^2 \) 也是特征值。
    - 所以，可以计算特征值 \( \lambda_1^2 = 4 \) 和 \( \lambda_2^2 = 25 \)。

### 总结
这一页首先回顾了之前获得的特征值和特征向量，然后引出了对新矩阵特征值和特征向量的讨论。这为理解特征值和特征向量在变换时的性质提供了良好的基础，引导读者思考如何通过对矩阵进行简单操作（如加常数或平方）来推导出新的特征值。
# 12-33
这一页展示了如何计算矩阵 \( B = A + 3I \) 的特征值和特征向量，其中矩阵 \( A \) 定义如下：

\[
A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
\]

### 新矩阵的定义
- 定义矩阵 \( B \) 为：
\[
B = A + 3I = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix} + 3 \begin{pmatrix} 1 & 0 \\ 0 & 1 \end{pmatrix} = \begin{pmatrix} 7 & 2 \\ 1 & 6 \end{pmatrix}
\]

### 计算特征值
- 为了计算特征值，我们需要解方程：
\[
\text{det}(B - \lambda I) = 0
\]
- 首先计算 \( B - \lambda I \)：
\[
B - \lambda I = \begin{pmatrix} 7 - \lambda & 2 \\ 1 & 6 - \lambda \end{pmatrix}
\]
- 然后求行列式：
\[
\text{det}(B - \lambda I) = (7 - \lambda)(6 - \lambda) - 2 \times 1
\]
- 展开后得：
\[
(7 - \lambda)(6 - \lambda) - 2 = 42 - 7\lambda - 6\lambda + \lambda^2 - 2 = \lambda^2 - 13\lambda + 40
\]
- 设这个等式等于零：
\[
\lambda^2 - 13\lambda + 40 = 0
\]
- 使用求根公式或因式分解，可以找到特征值：
\[
\lambda_1 = 5 \quad \text{和} \quad \lambda_2 = 8
\]

### 计算特征向量
#### 对于特征值 \( \lambda_1 = 5 \)
1. 代入特征值 \( 5 \) 到方程 \( B - \lambda I \)：
   \[
   B - 5I = \begin{pmatrix} 2 & 2 \\ 1 & 1 \end{pmatrix}
   \]
2. 解方程 \( (B - 5I)x = 0 \)：
   \[
   \begin{pmatrix} 2 & 2 \\ 1 & 1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 由此得到：
   - \( 2x_1 + 2x_2 = 0 \)
   - \( x_1 + x_2 = 0 \)
4. 因此，特征向量为：
   \[
   x = \begin{pmatrix} 1 \\ -1 \end{pmatrix}
   \]

#### 对于特征值 \( \lambda_2 = 8 \)
1. 代入特征值 \( 8 \) 到方程 \( B - 8I \)：
   \[
   B - 8I = \begin{pmatrix} -1 & 2 \\ 1 & -2 \end{pmatrix}
   \]
2. 解方程 \( (B - 8I)x = 0 \)：
   \[
   \begin{pmatrix} -1 & 2 \\ 1 & -2 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 从中得到：
   - \( -x_1 + 2x_2 = 0 \)
   - \( x_1 - 2x_2 = 0 \)
4. 特征向量为：
   \[
   x = \begin{pmatrix} 2 \\ 1 \end{pmatrix}
   \]

### 总结
这一页展示了如何计算矩阵 \( B = A + 3I \) 的特征值和特征向量。通过对行列式的求解得到两个特征值，并进一步计算了它们对应的特征向量。这是应用矩阵属性实用示例的重要组成部分，帮助理解特征值与特征向量之间的关系。
# 13-33
这一页强调了矩阵 \( A \) 和 \( B = A + 3I \) 的特征向量与特征值之间的关系。

### 矩阵 \( A \) 和 \( B \) 的特征值与特征向量
- **矩阵 \( A \)**：
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]
  - 特征值：
    - \( \lambda_1 = 2 \)
    - \( \lambda_2 = 5 \)
  - 对应的特征向量：
    - 对于 \( \lambda_1 = 2 \)，特征向量为 
      \[
      \begin{pmatrix} 1 \\ -1 \end{pmatrix}
      \]
    - 对于 \( \lambda_2 = 5 \)，特征向量为 
      \[
      \begin{pmatrix} 2 \\ 1 \end{pmatrix}
      \]

- **矩阵 \( B \)**：
  \[
  B = A + 3I = \begin{pmatrix} 7 & 2 \\ 1 & 6 \end{pmatrix}
  \]
  - 特征值：
    - \( \lambda_1 = 5 \)
    - \( \lambda_2 = 8 \)
  - 对应的特征向量：
    - 对于 \( \lambda_1 = 5 \)，特征向量为 
      \[
      \begin{pmatrix} 1 \\ -1 \end{pmatrix}
      \]
    - 对于 \( \lambda_2 = 8 \)，特征向量为 
      \[
      \begin{pmatrix} 2 \\ 1 \end{pmatrix}
      \]

### 特征向量的相同性
- 这页指出，矩阵 \( A \) 和 \( A + 3I \) 的特征向量是相同的。

### 特征值的关系
- 矩阵 \( A + 3I \) 的特征值是通过将矩阵 \( A \) 的特征值加上 3 得到的。
  - 具体来说，对于任何特征值 \( \lambda \)，在 \( A \) 中，如果 \( A x = \lambda x \)，则在 \( A + cI \) 的情况下会得到 \( (A + cI)x = (\lambda + c)x \)。

### 总结
这一页强调了矩阵 \( A + 3I \) 的特征值和特征向量的计算结果，并解释了它们之间的关系。通过添加常数 \( c \) 影响特征值而不影响特征向量，这种性质在处理线性变换时非常重要。这为理解矩阵的谱特性提供了一个直观的框架。
# 14-33
这一页展示了如何计算矩阵 \( A^2 \) 的特征值和特征向量。以下是详细讲解：

### 矩阵 \( A \) 和 \( B \) 的定义
- 矩阵 \( A \) 定义为：
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]
- 令 \( B \) 为 \( A^2 \)：
  \[
  B = A^2 = A \cdot A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix} \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix} = \begin{pmatrix} 18 & 14 \\ 7 & 11 \end{pmatrix}
  \]

### 计算特征值
- 为了计算特征值，首先求解下列方程：
\[
\text{det}(B - \lambda I) = 0
\]
- 计算 \( B - \lambda I \)：
\[
B - \lambda I = \begin{pmatrix} 18 - \lambda & 14 \\ 7 & 11 - \lambda \end{pmatrix}
\]
- 计算行列式：
\[
\text{det}(B - \lambda I) = (18 - \lambda)(11 - \lambda) - 14 \times 7
\]
- 展开得到：
\[
(18 - \lambda)(11 - \lambda) - 98 = 198 - 29\lambda + \lambda^2 - 98 = \lambda^2 - 29\lambda + 100
\]
- 将其设为零：
\[
\lambda^2 - 29\lambda + 100 = 0
\]
- 通过求解该方程，找到特征值：
\[
(\lambda - 4)(\lambda - 25) = 0
\]
因此，特征值为 \( \lambda_1 = 4 \) 和 \( \lambda_2 = 25 \)。

### 计算特征向量
#### 对于特征值 \( \lambda_1 = 4 \)
1. 代入特征值到 \( B - 4I \)：
   \[
   B - 4I = \begin{pmatrix} 18 - 4 & 14 \\ 7 & 11 - 4 \end{pmatrix} = \begin{pmatrix} 14 & 14 \\ 7 & 7 \end{pmatrix}
   \]

2. 解方程 \( (B - 4I)x = 0 \)：
   \[
   \begin{pmatrix} 14 & 14 \\ 7 & 7 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 得到以下方程：
   - \( 14x_1 + 14x_2 = 0 \) 
   - \( x_1 + x_2 = 0 \)

4. 所得到的特征向量为：
   \[
   x = \begin{pmatrix} 1 \\ -1 \end{pmatrix}
   \]

#### 对于特征值 \( \lambda_2 = 25 \)
1. 代入特征值到 \( B - 25I \)：
   \[
   B - 25I = \begin{pmatrix} 18 - 25 & 14 \\ 7 & 11 - 25 \end{pmatrix} = \begin{pmatrix} -7 & 14 \\ 7 & -14 \end{pmatrix}
   \]

2. 解方程 \( (B - 25I)x = 0 \)：
   \[
   \begin{pmatrix} -7 & 14 \\ 7 & -14 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \end{pmatrix}
   \]
3. 得到以下方程：
   - \( -7x_1 + 14x_2 = 0 \)
   - \( x_1 - 2x_2 = 0 \)

4. 所得到的特征向量为：
   \[
   x = \begin{pmatrix} 2 \\ 1 \end{pmatrix}
   \]

### 总结
这一页展示了如何计算矩阵 \( A^2 \) 的特征值和特征向量，分别得到了特征值 \( 4 \) 和 \( 25 \)，并通过解线性方程组得到了相应的特征向量。这为理解特征值与特征向量的关系提供了具体示例，并展示了二次运算对矩阵特征值的影响。
# 15-33
这一页总结了关于矩阵 \( A \) 和它的平方矩阵 \( A^2 \) 的特征值和特征向量的重要关系。

### 矩阵 \( A \) 的特征值与特征向量
- 矩阵 \( A \) 定义为：
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]
- 其特征值和特征向量分别为：
  - 特征值 \( \lambda_1 = 2 \) 对应的特征向量为 
    \[
    \begin{pmatrix} 1 \\ -1 \end{pmatrix}
    \]
  - 特征值 \( \lambda_2 = 5 \) 对应的特征向量为 
    \[
    \begin{pmatrix} 2 \\ 1 \end{pmatrix}
    \]

### 矩阵 \( B \) 的定义
- 矩阵 \( B \) 定义为：
  \[
  B = A^2 = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix} \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix} = \begin{pmatrix} 18 & 14 \\ 7 & 11 \end{pmatrix}
  \]
- 其特征值和特征向量分别为：
  - 特征值 \( \lambda_1 = 4 \) 对应的特征向量为 
    \[
    \begin{pmatrix} 1 \\ -1 \end{pmatrix}
    \]
  - 特征值 \( \lambda_2 = 25 \) 对应的特征向量为 
    \[
    \begin{pmatrix} 2 \\ 1 \end{pmatrix}
    \]

### 特征向量的相同性
- 这一页强调，矩阵 \( A \) 和 和 \( A^2 \) 的特征向量是相同的。

### 特征值的关系
- \( \( A^2 \) 的特征值是 \( A \) 特征值的平方。
  - 具体来说，特征值关系如下：
    - 如果 \( Ax = \lambda x \)，那么 \( A^2 x = A(\lambda x) = \lambda(Ax) = \lambda^2 x \)。

### 总结
这一页概述了矩阵 \( A \) 和 \( A^2 \) 的特征值与特征向量的关系。特征向量保持不变，而特征值则通过平方运算得到。这种性质在分析矩阵时对其谱特性有重要意义，特别是在理解如何通过矩阵的操作来推导出新的特征值与特征向量时。
# 16-33
这一页介绍了一些与特征值相关的重要事实，特别是特征值和矩阵对角元素之间的关系。

### 矩阵 \( A \)、\( B = A + 3I \) 和 \( B = A^2 \) 的特征值
- 矩阵 \( A \) 定义为：
  \[
  A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
  \]
  - 特征值：
    - \( \lambda_1 = 2 \)
    - \( \lambda_2 = 5 \)

- 矩阵 \( B = A + 3I \) 定义为：
  \[
  B = \begin{pmatrix} 7 & 2 \\ 1 & 6 \end{pmatrix}
  \]
  - 特征值：
    - \( \lambda_1 = 5 \)
    - \( \lambda_2 = 8 \)

- 矩阵 \( B = A^2 \) 定义为：
  \[
  B = \begin{pmatrix} 18 & 14 \\ 7 & 11 \end{pmatrix}
  \]
  - 特征值：
    - \( \lambda_1 = 4 \)
    - \( \lambda_2 = 25 \)

### 特征值与对角元素的关系
- **特征值的求和**：
  - 矩阵的 \( n \) 个特征值的总和等于矩阵的 \( n \) 个对角元素的总和。
  - 例如：
    - 对于矩阵 \( A \)：
      - 对角元素为 \( 4 + 3 = 7 \)
      - 特征值和为 \( 2 + 5 = 7 \)

- **迹的定义**：
  - 对角元素的和被称为矩阵的 **迹**（trace）。
  - 迹的定义为：
  \[
  \text{tr}(A) = \sum_{i=1}^{n} a_{ii}
  \]
  - 这里 \( a_{ii} \) 表示矩阵 \( A \) 的第 \( i \) 个对角元素。

### 总结
这一页强调了特征值与矩阵对角元素之间的关系，说明了特征值的总和等于对角元素的总和，并介绍了迹的概念。这些概念在矩阵理论和线性代数中具有重要意义，帮助理解矩阵性质与特征值之间的联系。
# 17-33
这一页总结了与特征值相关的重要事实，特别是关于特征值的乘积与行列式之间的关系。

### 矩阵及其特征值
1. **矩阵 \( A \)**:
   \[
   A = \begin{pmatrix} 4 & 2 \\ 1 & 3 \end{pmatrix}
   \]
   - 特征值：
     - \( \lambda_1 = 2 \)
     - \( \lambda_2 = 5 \)
   - 特征值的乘积：
     - \( \lambda_1 \lambda_2 = 2 \times 5 = 10 \)
   - 行列式：
     - \( \text{det}(A) = 10 \)

2. **矩阵 \( B = A + 3I \)**:
   \[
   B = \begin{pmatrix} 7 & 2 \\ 1 & 6 \end{pmatrix}
   \]
   - 特征值：
     - \( \lambda_1 = 5 \)
     - \( \lambda_2 = 8 \)
   - 特征值的乘积：
     - \( \lambda_1 \lambda_2 = 5 \times 8 = 40 \)
   - 行列式：
     - \( \text{det}(B) = 40 \)

3. **矩阵 \( B = A^2 \)**:
   \[
   B = \begin{pmatrix} 18 & 14 \\ 7 & 11 \end{pmatrix}
   \]
   - 特征值：
     - \( \lambda_1 = 4 \)
     - \( \lambda_2 = 25 \)
   - 特征值的乘积：
     - \( \lambda_1 \lambda_2 = 4 \times 25 = 100 \)
   - 行列式：
     - \( \text{det}(B) = 100 \)

### 特征值乘积与行列式的关系
- **总结**: 
  - 所有 \( n \) 个特征值的乘积等于矩阵的行列式。
  - 例如：
    - 对于矩阵 \( A \)，特征值乘积 \( 10 \) 等于行列式 \( \text{det}(A) = 10 \)。
    - 对于矩阵 \( B \)（\( A + 3I \)），特征值乘积 \( 40 \) 等于行列式 \( \text{det}(B) = 40 \)。
    - 对于矩阵 \( B \)（\( A^2 \)），特征值乘积 \( 100 \) 等于行列式 \( \text{det}(B) = 100 \)。

### 结论
这一页强调了特征值的乘积与行列式之间的密切关系。这是线性代数中一个非常重要的性质，有助于我们理解矩阵的结构和特性，以及在进行相关计算时的简化。
# 18-33
这一页介绍了矩阵 \( A \) 的特征分解（Eigen-Decomposition）概念。

### 矩阵的特征分解
- 假设有一个 \( n \) 阶矩阵 \( A \)，且其具有 \( n \) 个线性独立的特征向量 \( x_1, x_2, \ldots, x_n \)。
- 这些特征向量可以按列放入一个特征向量矩阵 \( X \) 中。

### 特征分解公式
通过特征向量进行的矩阵分解有如下表示：
\[
AX = A \begin{pmatrix} x_1 & \dots & x_n \end{pmatrix}
\]
- 这里，矩阵 \( X \) 包含了特征向量作为列，即：
\[
X = \begin{pmatrix} x_1 & \dots & x_n \end{pmatrix}
\]
- 则根据特征向量的性质，可以得到：
\[
AX = \begin{pmatrix} \lambda_1 x_1 & \dots & \lambda_n x_n \end{pmatrix}
\]
- 这里，\( \lambda_1, \lambda_2, \ldots, \lambda_n \) 是对应于各特征向量的特征值。

### 矩阵表示
将特征向量矩阵 \( X \) 和特征值矩阵 \( \Lambda \) 结合，矩阵 \( AX \) 可以表示成：
\[
AX = X \Lambda
\]
- 其中：
  \[
  \Lambda = \begin{pmatrix} \lambda_1 & 0 & \dots & 0 \\ 0 & \lambda_2 & \dots & 0 \\ \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \dots & \lambda_n \end{pmatrix}
  \]
- 这是一个对角矩阵，包含了所有的特征值。

### 总结
这一页描述了矩阵 \( A \) 的特征分解过程，强调了特征向量和特征值之间的关系，以及如何通过特征向量矩阵和特征值矩阵来表达矩阵 \( A \) 的性质。这是线性代数中特征值和特征向量的应用基础，使我们能够将矩阵表示为其特征向量和特征值的组合。这种分解在许多领域中都非常重要，比如在定量分析、机器学习和物理等领域。
